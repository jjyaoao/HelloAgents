"""
Win Rate è¯„ä¼°è„šæœ¬ - Universal ç‰ˆæœ¬

æœ¬è„šæœ¬å±•ç¤ºé€šç”¨ Win Rate è¯„ä¼°å™¨åœ¨å®é™…åº”ç”¨ä¸­çš„å„ç§ä½¿ç”¨æ–¹å¼ã€‚

å…³é”®ç‰¹ç‚¹ï¼š
1. å¤šæ¨¡æ¿æ”¯æŒï¼šmath, code, writing, qa
2. å­—æ®µæ˜ å°„ï¼šå¤„ç†ä¸åŒæ•°æ®æ ¼å¼çš„è‡ªé€‚åº”å¯¹é½
3. è‡ªå®šä¹‰ç»´åº¦ï¼šæ ¹æ®æ¨¡æ¿è‡ªåŠ¨è°ƒæ•´è¯„ä¼°ç»´åº¦
4. çœŸå®åœºæ™¯ï¼šæ¨¡æ‹Ÿå®é™…ä½¿ç”¨ä¸­çš„å„ç§æƒ…å†µ

æ¡ˆä¾‹ 1ï¼šç›´æ¥ä½¿ç”¨è¯„ä¼°å™¨ï¼ˆä¸‰ä¸ªçœŸå®åœºæ™¯ï¼‰
  åœºæ™¯ Aï¼šæ•°å­¦é¢˜ Win Rate å¯¹æ¯”ï¼ˆæ ‡å‡†å­—æ®µ + math æ¨¡æ¿ï¼‰
  åœºæ™¯ Bï¼šä»£ç  Win Rate å¯¹æ¯”ï¼ˆå­—æ®µæ˜ å°„ + code æ¨¡æ¿ï¼‰
  åœºæ™¯ Cï¼šå†™ä½œ Win Rate å¯¹æ¯”ï¼ˆå­—æ®µæ˜ å°„ + writing æ¨¡æ¿ï¼‰

æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·ï¼ˆä¸€è¡Œæå®šï¼‰
  è‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€å­—æ®µæ˜ å°„ã€æ¨¡æ¿åˆ‡æ¢ã€æŠ¥å‘Šç”Ÿæˆ
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from hello_agents import (
    HelloAgentsLLM,
    UniversalWinRateEvaluator,
    UniversalWinRateTool,
)
from hello_agents.evaluation.benchmarks.data_generation_Universal.evaluation_config import (
    EvaluationConfig,
)

# ============================================================================
# æµ‹è¯•æ•°æ®å‡†å¤‡ï¼ˆçœŸå®åœºæ™¯æ•°æ®ï¼ŒåŒ…å«ä¸åŒå­—æ®µåï¼‰
# ============================================================================


def prepare_test_data():
    """å‡†å¤‡ä¸‰ç§ä¸åŒæ¨¡æ¿çš„æµ‹è¯•æ•°æ®ï¼ˆç”Ÿæˆæ•°æ®å’Œå‚è€ƒæ•°æ®ï¼‰"""

    # åœºæ™¯ Aï¼šæ•°å­¦é¢˜ï¼ˆæ ‡å‡†å­—æ®µåï¼‰
    math_generated = [
        {
            "id": "math_gen_001",
            "problem": "Find the number of positive integers $n$ such that $n^2 + 19n + 92$ is a perfect square.",
            "answer": "Using completing the square: $(2n+19)^2 - 4m^2 = -7$. Solve the Pell-like equation.",
        },
        {
            "id": "math_gen_002",
            "problem": "In triangle ABC with sides AB=13, BC=14, CA=15, find the area.",
            "answer": "Using Heron's formula: $s=21$, Area $= \\sqrt{21 \\cdot 8 \\cdot 7 \\cdot 6} = 84$.",
        },
    ]

    math_reference = [
        {
            "id": "math_ref_001",
            "problem": "Find the number of positive integers $n$ such that $n^2 + 19n + 92$ is a perfect square.",
            "answer": "Let $n^2 + 19n + 92 = m^2$. Complete the square and solve systematically.",
        },
        {
            "id": "math_ref_002",
            "problem": "In triangle ABC with sides AB=13, BC=14, CA=15, find the area.",
            "answer": "Use Heron's formula with semi-perimeter s=21.",
        },
    ]

    # åœºæ™¯ Bï¼šä»£ç è¯„ä¼°ï¼ˆéæ ‡å‡†å­—æ®µï¼šcode, expected_behaviorï¼‰
    code_generated = [
        {
            "id": "code_gen_001",
            "code": """
def fibonacci(n):
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(n):
        a, b = b, a + b
    return a
            """,
            "expected_behavior": "Returns correct fibonacci numbers efficiently",
            "context": "Optimized fibonacci implementation",
        },
        {
            "id": "code_gen_002",
            "code": """
def sort_array(arr):
    for i in range(len(arr)):
        for j in range(len(arr)-1-i):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr
            """,
            "expected_behavior": "Correctly sorted array in ascending order",
            "context": "Bubble sort implementation",
        },
    ]

    code_reference = [
        {
            "id": "code_ref_001",
            "code": """
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
            """,
            "expected_behavior": "Returns correct fibonacci numbers",
            "context": "Standard fibonacci implementation",
        },
        {
            "id": "code_ref_002",
            "code": """
def sort_array(arr):
    return sorted(arr)
            """,
            "expected_behavior": "Returns sorted array using built-in method",
            "context": "Simple sorting with Python built-in",
        },
    ]

    # åœºæ™¯ Cï¼šå†™ä½œè¯„ä¼°ï¼ˆéæ ‡å‡†å­—æ®µï¼šcontent, targetï¼‰
    writing_generated = [
        {
            "id": "writing_gen_001",
            "content": "Python is a high-level, interpreted programming language known for its simplicity and readability. It supports multiple programming paradigms including procedural, object-oriented, and functional programming. The language emphasizes code readability.",
            "target": "Technical article about Python",
            "length": "medium",
        },
        {
            "id": "writing_gen_002",
            "content": "Machine learning is revolutionizing how we approach data analysis. With algorithms that can learn patterns from data, ML enables computers to make predictions without explicit programming. This technology is transforming industries globally.",
            "target": "Educational blog post about ML",
            "length": "medium",
        },
    ]

    writing_reference = [
        {
            "id": "writing_ref_001",
            "content": "Python is a versatile programming language that combines simplicity with power. It has become the go-to language for beginners and experts alike.",
            "target": "Technical article about Python",
            "length": "short",
        },
        {
            "id": "writing_ref_002",
            "content": "Machine learning represents a significant shift in how we process information and make decisions based on data.",
            "target": "Educational blog post about ML",
            "length": "short",
        },
    ]

    return (math_generated, math_reference, code_generated, code_reference, writing_generated, writing_reference)


def save_test_data():
    """ä¿å­˜æµ‹è¯•æ•°æ®åˆ°æ–‡ä»¶"""
    math_gen, math_ref, code_gen, code_ref, writing_gen, writing_ref = prepare_test_data()

    os.makedirs("./test_data", exist_ok=True)

    with open("./test_data/math_generated.json", "w", encoding="utf-8") as f:
        json.dump(math_gen, f, indent=2, ensure_ascii=False)

    with open("./test_data/math_reference.json", "w", encoding="utf-8") as f:
        json.dump(math_ref, f, indent=2, ensure_ascii=False)

    with open("./test_data/code_generated.json", "w", encoding="utf-8") as f:
        json.dump(code_gen, f, indent=2, ensure_ascii=False)

    with open("./test_data/code_reference.json", "w", encoding="utf-8") as f:
        json.dump(code_ref, f, indent=2, ensure_ascii=False)

    with open("./test_data/writing_generated.json", "w", encoding="utf-8") as f:
        json.dump(writing_gen, f, indent=2, ensure_ascii=False)

    with open("./test_data/writing_reference.json", "w", encoding="utf-8") as f:
        json.dump(writing_ref, f, indent=2, ensure_ascii=False)

    return math_gen, math_ref, code_gen, code_ref, writing_gen, writing_ref


# ============================================================================
# æ¡ˆä¾‹ 1ï¼šç›´æ¥ä½¿ç”¨è¯„ä¼°å™¨ï¼ˆä¸‰ä¸ªçœŸå®åœºæ™¯ï¼‰
# ============================================================================


def example_scene_a_math():
    """
    åœºæ™¯ Aï¼šæ•°å­¦é¢˜ Win Rate å¯¹æ¯”

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨ "math" æ¨¡æ¿
    - æ ‡å‡†å­—æ®µåï¼ˆproblem, answerï¼‰
    - æ— éœ€å­—æ®µæ˜ å°„
    - å¯¹æ¯”ç»´åº¦ï¼šcorrectness, clarity, completeness, difficulty_match, originality
    """
    print("\n" + "="*70)
    print("ğŸ“Œ æ¡ˆä¾‹ 1 - åœºæ™¯ Aï¼šæ•°å­¦é¢˜ Win Rate å¯¹æ¯”ï¼ˆæ ‡å‡†å­—æ®µ + math æ¨¡æ¿ï¼‰")
    print("="*70)

    from hello_agents import HelloAgentsLLM, UniversalWinRateEvaluator
    from hello_agents.evaluation.benchmarks.data_generation_Universal.evaluation_config import (
        EvaluationConfig,
    )

    math_gen, math_ref, _, _, _, _ = save_test_data()

    # åˆ›å»º LLM å’Œè¯„ä¼°å™¨ï¼ˆä½¿ç”¨ math æ¨¡æ¿ï¼‰
    print("\n[åˆå§‹åŒ–] åˆ›å»º LLM å’Œè¯„ä¼°å™¨...")
    llm = HelloAgentsLLM(provider="deepseek", model="deepseek-chat")
    eval_config = EvaluationConfig.load_template("math")
    evaluator = UniversalWinRateEvaluator(llm=llm, eval_config=eval_config)
    print(f"âœ“ è¯„ä¼°å™¨å·²åˆå§‹åŒ–ï¼ˆæ¨¡æ¿: mathï¼‰")
    print(f"âœ“ å¯¹æ¯”ç»´åº¦: {', '.join(eval_config.get_dimension_names())}")

    # è¿›è¡Œ Win Rate å¯¹æ¯”
    print("\n[è¯„ä¼°] å¼€å§‹è¿›è¡Œ Win Rate å¯¹æ¯”...")
    print("="*70)
    print("ğŸ¯ Math é¢˜ç›® Win Rate å¯¹æ¯”")
    print("="*70)

    result = evaluator.evaluate_win_rate(math_gen, math_ref, num_comparisons=2)

    print(f"\nè¯„ä¼°ç»“æœ:")
    print(f"  èƒœç‡: {result.get('win_rate', 'N/A')}")
    print(f"  èƒœåœºæ•°: {result.get('wins', 'N/A')}")
    print(f"  å¹³å±€æ•°: {result.get('ties', 'N/A')}")
    print(f"  è´Ÿåœºæ•°: {result.get('losses', 'N/A')}")

    # ä¿å­˜ç»“æœ
    print("\n[ä¿å­˜] ä¿å­˜è¯„ä¼°ç»“æœ...")
    os.makedirs("./evaluation_results", exist_ok=True)
    with open("./evaluation_results/scene_a_math_win_rate.json", "w", encoding="utf-8") as f:
        json.dump(
            {
                "scenario": "A_Math_WinRate",
                "template": "math",
                "field_mapping": "None (standard fields)",
                "generated_data": math_gen,
                "reference_data": math_ref,
                "results": result,
            },
            f,
            indent=2,
            ensure_ascii=False,
        )

    print("âœ“ ç»“æœå·²ä¿å­˜åˆ° ./evaluation_results/scene_a_math_win_rate.json")
    print("\nâœ… åœºæ™¯ A å®Œæˆï¼")


def example_scene_b_code():
    """
    åœºæ™¯ Bï¼šä»£ç  Win Rate å¯¹æ¯”

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨ "code" æ¨¡æ¿
    - éæ ‡å‡†å­—æ®µåï¼ˆcode, expected_behaviorï¼‰
    - éœ€è¦å­—æ®µæ˜ å°„ï¼šcode â†’ problem, expected_behavior â†’ answer
    - å¯¹æ¯”ç»´åº¦ï¼šcorrectness, robustness, efficiency, readability, style_compliance
    """
    print("\n" + "="*70)
    print("ğŸ“Œ æ¡ˆä¾‹ 1 - åœºæ™¯ Bï¼šä»£ç  Win Rate å¯¹æ¯”ï¼ˆå­—æ®µæ˜ å°„ + code æ¨¡æ¿ï¼‰")
    print("="*70)

    from hello_agents import HelloAgentsLLM, UniversalWinRateEvaluator
    from hello_agents.evaluation.benchmarks.data_generation_Universal.evaluation_config import (
        EvaluationConfig,
    )

    _, _, code_gen, code_ref, _, _ = save_test_data()

    # åˆ›å»º LLM å’Œè¯„ä¼°å™¨ï¼ˆä½¿ç”¨ code æ¨¡æ¿ + å­—æ®µæ˜ å°„ï¼‰
    print("\n[åˆå§‹åŒ–] åˆ›å»º LLM å’Œè¯„ä¼°å™¨...")
    llm = HelloAgentsLLM(provider="deepseek", model="deepseek-chat")
    eval_config = EvaluationConfig.load_template("code")

    # å®šä¹‰å­—æ®µæ˜ å°„ï¼ˆè‡ªé€‚åº”å¤„ç†ä¸åŒæ•°æ®æ ¼å¼ï¼‰
    field_mapping = {
        "problem": "code",                    # æºæ•°æ®ä¸­çš„ "code" å­—æ®µæ˜ å°„åˆ° "problem"
        "answer": "expected_behavior",        # æºæ•°æ®ä¸­çš„ "expected_behavior" å­—æ®µæ˜ å°„åˆ° "answer"
    }

    evaluator = UniversalWinRateEvaluator(
        llm=llm,
        eval_config=eval_config,
        field_mapping=field_mapping
    )
    print(f"âœ“ è¯„ä¼°å™¨å·²åˆå§‹åŒ–ï¼ˆæ¨¡æ¿: codeï¼‰")
    print(f"âœ“ å¯¹æ¯”ç»´åº¦: {', '.join(eval_config.get_dimension_names())}")
    print(f"âœ“ å­—æ®µæ˜ å°„: {field_mapping}")

    # è¿›è¡Œ Win Rate å¯¹æ¯”
    print("\n[è¯„ä¼°] å¼€å§‹è¿›è¡Œ Win Rate å¯¹æ¯”...")
    print("="*70)
    print("ğŸ¯ Code ä»£ç  Win Rate å¯¹æ¯”")
    print("="*70)

    result = evaluator.evaluate_win_rate(code_gen, code_ref, num_comparisons=2)

    print(f"\nè¯„ä¼°ç»“æœ:")
    print(f"  èƒœç‡: {result.get('win_rate', 'N/A')}")
    print(f"  èƒœåœºæ•°: {result.get('wins', 'N/A')}")
    print(f"  å¹³å±€æ•°: {result.get('ties', 'N/A')}")
    print(f"  è´Ÿåœºæ•°: {result.get('losses', 'N/A')}")

    # ä¿å­˜ç»“æœ
    print("\n[ä¿å­˜] ä¿å­˜è¯„ä¼°ç»“æœ...")
    os.makedirs("./evaluation_results", exist_ok=True)
    with open("./evaluation_results/scene_b_code_win_rate.json", "w", encoding="utf-8") as f:
        json.dump(
            {
                "scenario": "B_Code_FieldMapping",
                "template": "code",
                "field_mapping": field_mapping,
                "generated_data": code_gen,
                "reference_data": code_ref,
                "results": result,
            },
            f,
            indent=2,
            ensure_ascii=False,
        )

    print("âœ“ ç»“æœå·²ä¿å­˜åˆ° ./evaluation_results/scene_b_code_win_rate.json")
    print("\nâœ… åœºæ™¯ B å®Œæˆï¼")


def example_scene_c_writing():
    """
    åœºæ™¯ Cï¼šå†™ä½œ Win Rate å¯¹æ¯”

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨ "writing" æ¨¡æ¿
    - éæ ‡å‡†å­—æ®µåï¼ˆcontent, targetï¼‰
    - éœ€è¦å­—æ®µæ˜ å°„ï¼šcontent â†’ problem, target â†’ answer
    - å¯¹æ¯”ç»´åº¦ï¼šaccuracy, coherence, richness, creativity_style, engagement
    """
    print("\n" + "="*70)
    print("ğŸ“Œ æ¡ˆä¾‹ 1 - åœºæ™¯ Cï¼šå†™ä½œ Win Rate å¯¹æ¯”ï¼ˆå­—æ®µæ˜ å°„ + writing æ¨¡æ¿ï¼‰")
    print("="*70)

    from hello_agents import HelloAgentsLLM, UniversalWinRateEvaluator
    from hello_agents.evaluation.benchmarks.data_generation_Universal.evaluation_config import (
        EvaluationConfig,
    )

    _, _, _, _, writing_gen, writing_ref = save_test_data()

    # åˆ›å»º LLM å’Œè¯„ä¼°å™¨ï¼ˆä½¿ç”¨ writing æ¨¡æ¿ + å­—æ®µæ˜ å°„ï¼‰
    print("\n[åˆå§‹åŒ–] åˆ›å»º LLM å’Œè¯„ä¼°å™¨...")
    llm = HelloAgentsLLM(provider="deepseek", model="deepseek-chat")
    eval_config = EvaluationConfig.load_template("writing")

    # å®šä¹‰å­—æ®µæ˜ å°„ï¼ˆè‡ªé€‚åº”å¤„ç†ä¸åŒæ•°æ®æ ¼å¼ï¼‰
    field_mapping = {
        "problem": "content",           # æºæ•°æ®ä¸­çš„ "content" å­—æ®µæ˜ å°„åˆ° "problem"
        "answer": "target",             # æºæ•°æ®ä¸­çš„ "target" å­—æ®µæ˜ å°„åˆ° "answer"
    }

    evaluator = UniversalWinRateEvaluator(
        llm=llm,
        eval_config=eval_config,
        field_mapping=field_mapping
    )
    print(f"âœ“ è¯„ä¼°å™¨å·²åˆå§‹åŒ–ï¼ˆæ¨¡æ¿: writingï¼‰")
    print(f"âœ“ å¯¹æ¯”ç»´åº¦: {', '.join(eval_config.get_dimension_names())}")
    print(f"âœ“ å­—æ®µæ˜ å°„: {field_mapping}")

    # è¿›è¡Œ Win Rate å¯¹æ¯”
    print("\n[è¯„ä¼°] å¼€å§‹è¿›è¡Œ Win Rate å¯¹æ¯”...")
    print("="*70)
    print("ğŸ¯ Writing å†™ä½œ Win Rate å¯¹æ¯”")
    print("="*70)

    result = evaluator.evaluate_win_rate(writing_gen, writing_ref, num_comparisons=2)

    print(f"\nè¯„ä¼°ç»“æœ:")
    print(f"  èƒœç‡: {result.get('win_rate', 'N/A')}")
    print(f"  èƒœåœºæ•°: {result.get('wins', 'N/A')}")
    print(f"  å¹³å±€æ•°: {result.get('ties', 'N/A')}")
    print(f"  è´Ÿåœºæ•°: {result.get('losses', 'N/A')}")

    # ä¿å­˜ç»“æœ
    print("\n[ä¿å­˜] ä¿å­˜è¯„ä¼°ç»“æœ...")
    os.makedirs("./evaluation_results", exist_ok=True)
    with open("./evaluation_results/scene_c_writing_win_rate.json", "w", encoding="utf-8") as f:
        json.dump(
            {
                "scenario": "C_Writing_FieldMapping",
                "template": "writing",
                "field_mapping": field_mapping,
                "generated_data": writing_gen,
                "reference_data": writing_ref,
                "results": result,
            },
            f,
            indent=2,
            ensure_ascii=False,
        )

    print("âœ“ ç»“æœå·²ä¿å­˜åˆ° ./evaluation_results/scene_c_writing_win_rate.json")
    print("\nâœ… åœºæ™¯ C å®Œæˆï¼")


# ============================================================================
# æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·ï¼ˆä¸€è¡Œæå®šï¼‰
# ============================================================================


def example_high_level_tool():
    """
    æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·

    ä¼˜ç‚¹ï¼š
    - ä¸€è¡Œä»£ç æå®šå®Œæ•´æµç¨‹
    - è‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€å­—æ®µæ˜ å°„ã€æŠ¥å‘Šç”Ÿæˆ
    - æ”¯æŒå¤šæ¨¡æ¿å’Œå¤šæ•°æ®æº
    """
    print("\n" + "="*70)
    print("ğŸ“Œ æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·ï¼ˆUniversalWinRateToolï¼‰")
    print("="*70)

    from hello_agents import HelloAgentsLLM, UniversalWinRateTool

    math_gen, math_ref, _, _, _, _ = save_test_data()

    print("\n[åˆå§‹åŒ–] åˆ›å»º LLM å’Œå·¥å…·...")
    llm = HelloAgentsLLM(provider="deepseek", model="deepseek-chat")
    tool = UniversalWinRateTool(template="math", llm=llm)
    print("âœ“ å·¥å…·å·²åˆå§‹åŒ–")

    print("\n[è¿è¡Œ] è°ƒç”¨ run() æ–¹æ³•è¿›è¡Œå®Œæ•´è¯„ä¼°...")

    # ä¿å­˜æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_gen_path = "./test_data/temp_math_generated.json"
    temp_ref_path = "./test_data/temp_math_reference.json"
    os.makedirs(os.path.dirname(temp_gen_path), exist_ok=True)
    with open(temp_gen_path, "w", encoding="utf-8") as f:
        json.dump(math_gen, f, indent=2, ensure_ascii=False)
    with open(temp_ref_path, "w", encoding="utf-8") as f:
        json.dump(math_ref, f, indent=2, ensure_ascii=False)

    result = tool.run({
        "generated_config": {"path": temp_gen_path},
        "generated_field_mapping": {"problem": "problem", "answer": "answer"},
        "reference_config": {"path": temp_ref_path},
        "reference_field_mapping": {"problem": "problem", "answer": "answer"},
        "template": "math",
        "num_comparisons": 2,
        "output_dir": "evaluation_results/case2_high_level"
    })

    print("\n" + "="*70)
    print("è¯„ä¼°å®Œæˆï¼ˆé«˜çº§å·¥å…·è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šå’Œç»Ÿè®¡ï¼‰")
    print("="*70)
    print(f"\nè¯„ä¼°ç»“æœ:\n{result}")

    print("\nâœ… æ¡ˆä¾‹ 2 å®Œæˆï¼")


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ¯ Win Rate è¯„ä¼°å·¥å…· - Universal ç‰ˆæœ¬")
    print("="*70)

    # print("\næœ¬è„šæœ¬æ¼”ç¤ºé€šç”¨è¯„ä¼°å™¨åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨ï¼š")
    # print("\nğŸ“Œ æ¡ˆä¾‹ 1ï¼šç›´æ¥ä½¿ç”¨è¯„ä¼°å™¨ï¼ˆçµæ´»ã€é€æ˜ï¼‰")
    # print("  åœºæ™¯ Aï¼šæ•°å­¦é¢˜ - æ ‡å‡†å­—æ®µ + math æ¨¡æ¿")
    # print("  åœºæ™¯ Bï¼šä»£ç    - å­—æ®µæ˜ å°„ + code æ¨¡æ¿")
    # print("  åœºæ™¯ Cï¼šå†™ä½œ   - å­—æ®µæ˜ å°„ + writing æ¨¡æ¿")
    # print("\nğŸ“Œ æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·ï¼ˆç®€æ´ã€è‡ªåŠ¨åŒ–ï¼‰")

    # è¿è¡Œæ¡ˆä¾‹ 1 çš„ä¸‰ä¸ªåœºæ™¯
    print("\n" + "="*70)
    print("å¼€å§‹æ¡ˆä¾‹ 1ï¼šç›´æ¥ä½¿ç”¨è¯„ä¼°å™¨")
    print("="*70)

    # example_scene_a_math()
    # example_scene_b_code()      # å–æ¶ˆæ³¨é‡Šæ¥è¿è¡Œåœºæ™¯ B
    # example_scene_c_writing()   # å–æ¶ˆæ³¨é‡Šæ¥è¿è¡Œåœºæ™¯ C

    # è¿è¡Œæ¡ˆä¾‹ 2
    print("\n" + "="*70)
    print("å¼€å§‹æ¡ˆä¾‹ 2ï¼šä½¿ç”¨é«˜çº§å·¥å…·")
    print("="*70)
    example_high_level_tool()   # å–æ¶ˆæ³¨é‡Šæ¥è¿è¡Œæ¡ˆä¾‹ 2

    # æ€»ç»“
    # print("\n" + "="*70)
    # print("ğŸ“Š å…³é”®è¦ç‚¹æ€»ç»“")
    # print("="*70)

    # print("\nğŸ”‘ é€šç”¨è¯„ä¼°å™¨çš„æ ¸å¿ƒèƒ½åŠ›ï¼š")
    # print("\n1. å¤šæ¨¡æ¿æ”¯æŒï¼ˆFlexibleï¼‰")
    # print("   âœ“ mathï¼šæ•°å­¦é¢˜ - é‡è§†æ­£ç¡®æ€§ã€éš¾åº¦åŒ¹é…ã€åˆ›æ„è§£æ³•")
    # print("   âœ“ codeï¼šä»£ç    - é‡è§†é²æ£’æ€§ã€æ•ˆç‡ã€ä»£ç é£æ ¼")
    # print("   âœ“ writingï¼šå†™ä½œ - é‡è§†å‡†ç¡®æ€§ã€è¿è´¯æ€§ã€åˆ›æ„è¡¨è¾¾")
    # print("   âœ“ qaï¼šé—®ç­”   - é‡è§†å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€æœ‰ç”¨æ€§")

    # print("\n2. å­—æ®µæ˜ å°„ï¼ˆAdaptiveï¼‰")
    # print("   âœ“ è‡ªåŠ¨å¤„ç†ä¸åŒæ•°æ®æ ¼å¼")
    # print("   âœ“ æ”¯æŒéæ ‡å‡†å­—æ®µå")
    # print("   âœ“ æ— éœ€ä¿®æ”¹æºæ•°æ®")

    # print("\n3. ä¸¤å±‚çº§ä½¿ç”¨ï¼ˆFlexible Hierarchyï¼‰")
    # print("   ä½å±‚çº§ï¼šUniversalWinRateEvaluator - çµæ´»å®šåˆ¶")
    # print("   é«˜å±‚çº§ï¼šUniversalWinRateTool - å¿«é€Ÿéƒ¨ç½²")

    # print("\nâœ… æ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„ä½¿ç”¨æ–¹å¼ï¼")
